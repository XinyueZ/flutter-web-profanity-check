{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "profanity_check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLbP70E/H6uz8+4k5XaK3b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinyueZ/flutter-web-profanity-check/blob/master/machine_learning/profanity_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEdwzLodYZ8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QAxRk_QYnVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import itertools\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYiXdRsK3jIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = keras.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIMZjQ_wYziS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6ab4823-0950-4074-a526-91f95487b951"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raXD5xU1Y1J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download dataset\n",
        "URL = \"https://dl.dropbox.com/s/ewpit86gekpiwk5/hate_dirty_peech_labeled_data.tsv\"\n",
        "path = tf.keras.utils.get_file(URL.split('/')[-1], URL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jd5izwxZFbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the data to a Pandas data frame\n",
        "data = pd.read_csv(path, sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGh-BZupZYvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5cc560f4-9086-4d1d-df24-64fcec3b050e"
      },
      "source": [
        "# Shuffle the data\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "# Print the first first five rows as default\n",
        "data.head()"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22565</th>\n",
              "      <td>23048</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Welp imma hoe again :/ RT @Gladvillian: She a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9916</th>\n",
              "      <td>10194</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>How is that not a yellow on Ronaldo for full o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>1021</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22716</th>\n",
              "      <td>23201</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>When niggas wanna cheat they start an argument...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12865</th>\n",
              "      <td>13191</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Molly's that bitch you love when she comes but...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                              tweet\n",
              "22565       23048  ...  Welp imma hoe again :/ RT @Gladvillian: She a ...\n",
              "9916        10194  ...  How is that not a yellow on Ronaldo for full o...\n",
              "992          1021  ...  &#128514;&#128514;&#128514;&#128514;&#128514;&...\n",
              "22716       23201  ...  When niggas wanna cheat they start an argument...\n",
              "12865       13191  ...  Molly's that bitch you love when she comes but...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vayQEeh0IJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "de1f59ff-a6d2-4e57-d5a0-09d4d069ef98"
      },
      "source": [
        "# Clean data\n",
        "data = data[pd.notnull(data['class'])]\n",
        "data = data[pd.notnull(data['tweet'])]\n",
        "data = data.drop(data.columns[0], axis=1) \n",
        "data = data.drop(columns=['count', 'hate_speech', 'offensive_language', 'neither']) \n",
        " \n",
        "# Print the first first five rows as default\n",
        "data.head()"
      ],
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22565</th>\n",
              "      <td>1</td>\n",
              "      <td>Welp imma hoe again :/ RT @Gladvillian: She a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9916</th>\n",
              "      <td>2</td>\n",
              "      <td>How is that not a yellow on Ronaldo for full o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22716</th>\n",
              "      <td>1</td>\n",
              "      <td>When niggas wanna cheat they start an argument...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12865</th>\n",
              "      <td>1</td>\n",
              "      <td>Molly's that bitch you love when she comes but...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet\n",
              "22565      1  Welp imma hoe again :/ RT @Gladvillian: She a ...\n",
              "9916       2  How is that not a yellow on Ronaldo for full o...\n",
              "992        1  &#128514;&#128514;&#128514;&#128514;&#128514;&...\n",
              "22716      1  When niggas wanna cheat they start an argument...\n",
              "12865      1  Molly's that bitch you love when she comes but..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjWjj-AcuW19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3733130d-7c17-4d74-939b-69854cf88b88"
      },
      "source": [
        "# Split data into train and test\n",
        "train_size = int(len(data) * .95)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(data) - train_size))"
      ],
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 23537\n",
            "Test size: 1239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubYRX8zDulje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features to train\n",
        "tweet_train = data['tweet'][:train_size]\n",
        "class_train = data['class'][:train_size]\n",
        "\n",
        "# Labels (class types)\n",
        "labels_train = data['class'][:train_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtI_IxF4vIUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features for test\n",
        "tweet_test = data['tweet'][train_size:]\n",
        "class_test = data['class'][train_size:]\n",
        "\n",
        "# Labels for test\n",
        "labels_test = data['class'][train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j3gc024xtmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 15000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df7fvZtEvl5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
        "tokenize.fit_on_texts(tweet_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVcTXjWyv-ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_train = tokenize.texts_to_matrix(tweet_train)\n",
        "bow_test = tokenize.texts_to_matrix(tweet_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z17N6DLBwaKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(class_train)\n",
        "class_train = encoder.transform(class_train)\n",
        "class_test = encoder.transform(class_test)\n",
        "num_classes = np.max(class_train) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxyDdsB7wm8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_train = keras.utils.to_categorical(class_train, num_classes)\n",
        "class_test = keras.utils.to_categorical(class_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW29eoPIw0PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_inputs = layers.Input(shape=(vocab_size,))\n",
        "class_inputs = layers.Input(shape=(num_classes,))\n",
        "merged_layer = layers.concatenate([bow_inputs, class_inputs])\n",
        "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
        "predictions = layers.Dense(1)(merged_layer)\n",
        "wide_model = keras.Model(inputs=[bow_inputs, class_inputs], outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhKIt_cFVckL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = \"mse\"\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHmKzUW0yQGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "5268fafe-71ef-4e07-f643-12932e90b83a"
      },
      "source": [
        "wide_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "wide_model.summary()"
      ],
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_34 (InputLayer)           [(None, 15000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 15003)        0           input_34[0][0]                   \n",
            "                                                                 input_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 256)          3841024     concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1)            257         dense_44[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 3,841,281\n",
            "Trainable params: 3,841,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "het-rWCeyTf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_embed = tokenize.texts_to_sequences(tweet_train)\n",
        "test_embed = tokenize.texts_to_sequences(tweet_test)\n",
        "\n",
        "max_seq_length = 170\n",
        "train_embed = keras.preprocessing.sequence.pad_sequences(train_embed, maxlen=max_seq_length, padding=\"post\")\n",
        "test_embed = keras.preprocessing.sequence.pad_sequences(test_embed, maxlen=max_seq_length, padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYk1CN48yfos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "edd78093-a6a0-473f-faed-b4ea3022ea94"
      },
      "source": [
        "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
        "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
        "embedding = layers.Flatten()(embedding)\n",
        "embed_out = layers.Dense(1)(embedding)\n",
        "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
        "deep_model.summary()"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_36 (InputLayer)        [(None, 170)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_11 (Embedding)     (None, 170, 8)            120000    \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1360)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1)                 1361      \n",
            "=================================================================\n",
            "Total params: 121,361\n",
            "Trainable params: 121,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8h2LdURzCBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deep_model.compile(loss=loss, optimizer=optimizer,  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaDpfzI-zKmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "3f8e3b38-a6f7-4070-f1ce-d47a38fda4f9"
      },
      "source": [
        "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
        "merged_out = layers.Dense(1)(merged_out)\n",
        "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
        "combined_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "combined_model.summary()"
      ],
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_34 (InputLayer)           [(None, 15000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_36 (InputLayer)           [(None, 170)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 15003)        0           input_34[0][0]                   \n",
            "                                                                 input_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 170, 8)       120000      input_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 256)          3841024     concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 1360)         0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1)            257         dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 1)            1361        flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 2)            0           dense_45[0][0]                   \n",
            "                                                                 dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 1)            3           concatenate_23[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 3,962,645\n",
            "Trainable params: 3,962,645\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvOrwHfaXA4W",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcaoQcM-VC4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeRxnt9mzg8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "2330c3ea-46c5-42e2-94a7-94e06d86069f"
      },
      "source": [
        "history = combined_model.fit([bow_train, class_train] + [train_embed], labels_train, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.0806 - accuracy: 0.8004\n",
            "Epoch 2/10\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.0118 - accuracy: 0.8315\n",
            "Epoch 3/10\n",
            "184/184 [==============================] - 11s 60ms/step - loss: 0.0054 - accuracy: 0.8318\n",
            "Epoch 4/10\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.0025 - accuracy: 0.8319\n",
            "Epoch 5/10\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.0014 - accuracy: 0.8319\n",
            "Epoch 6/10\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.0010 - accuracy: 0.8319\n",
            "Epoch 7/10\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 9.4004e-04 - accuracy: 0.8319\n",
            "Epoch 8/10\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 9.2886e-04 - accuracy: 0.8318\n",
            "Epoch 9/10\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 9.5062e-04 - accuracy: 0.8319\n",
            "Epoch 10/10\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 9.5874e-04 - accuracy: 0.8319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AXPzBxEzn3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "871908d3-b89b-4f7c-ddd0-f6cc277ad6f1"
      },
      "source": [
        "combined_model.evaluate([bow_test, class_test] + [test_embed], labels_test, batch_size=batch_size)"
      ],
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 0.8345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.002103975275531411, 0.8345440030097961]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlX3VPcHz5Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = combined_model.predict([bow_test, class_test] + [test_embed])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Edoojgg27PF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa522953-9722-4396-b664-965422ab04c5"
      },
      "source": [
        "num_predictions = 40\n",
        "diff = 0\n",
        "\n",
        "for i in range(num_predictions):\n",
        "    val = predictions[i]\n",
        "    print(tweet_test.iloc[i])\n",
        "    print('Predicted: ', val[0], 'Actual: ', labels_test.iloc[i], '\\n')\n",
        "    diff += abs(val[0] - labels_test.iloc[i])"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "&#8220;@Dedicated_03: Wassup twitter &#128518; http://t.co/rNeTkFXm7f&#8221; wassup bitch !!\n",
            "Predicted:  0.9822972 Actual:  1 \n",
            "\n",
            "@IIXIXIII bruhhh I'm joking... Don't pop trunk on me I'm just a bitch ass niiiieeegggaaa\n",
            "Predicted:  0.9659867 Actual:  1 \n",
            "\n",
            "@tyg235 @italian_montana have fun losing tonight bitch\n",
            "Predicted:  0.9666593 Actual:  1 \n",
            "\n",
            "RT @misstannaebaby: Niggas all about sex now days. Unlike you bitches, i jus want somebody who gone better me as a young women&#58400;\n",
            "Predicted:  1.0066032 Actual:  1 \n",
            "\n",
            "American culture is stuck to the side of the toilet. Graffiti writers in Europe can create better art without any lowlife trash sex jokes.\n",
            "Predicted:  1.9066012 Actual:  2 \n",
            "\n",
            "Lmao!! RT @CarmelIoAnthony: NOBODY cleans a house FASTER than a nigga expecting some pussy.\n",
            "Predicted:  1.0007035 Actual:  1 \n",
            "\n",
            "Don't bring dat police ass nicca round me\n",
            "Predicted:  1.008824 Actual:  1 \n",
            "\n",
            "&#8220;@DevJayAintShit: these hoes ain't loyal &#128557;  https://t.co/hiMKk7fYxB&#8221;&#128557;\n",
            "Predicted:  0.9967971 Actual:  1 \n",
            "\n",
            "RT @turk_jt12: That bitch ain't loyal.\n",
            "Predicted:  0.9959773 Actual:  1 \n",
            "\n",
            "&#8220;@Chrissy_Cindy: If a bitch tweet \"I lose interest fast\" slide in her DMs cause she a Thot&#8221; good looks\n",
            "Predicted:  1.002342 Actual:  1 \n",
            "\n",
            "@NoShtickZone I called him a pussy and got blocked real quick by him and Bobby Kelly. I cant say I upset about it.\n",
            "Predicted:  0.98891354 Actual:  1 \n",
            "\n",
            "@CarelessOne92 weeknd make muzik for the hoes b, im tryna meet these women he be talkin bout\n",
            "Predicted:  0.98627865 Actual:  1 \n",
            "\n",
            "@brrrrangadang this nigga &#128529;&#128529;.. know damn well you a coon\n",
            "Predicted:  0.058844987 Actual:  0 \n",
            "\n",
            "Smoke sesh niggah what u mean\n",
            "Predicted:  1.0128397 Actual:  1 \n",
            "\n",
            "Ima trash @ForeverMEM85 in fantasy\n",
            "Predicted:  1.9695781 Actual:  2 \n",
            "\n",
            "neither have i :-/ RT @DerekIsNormal: I just...why...ok. RT @pieceofshittbh: \"I've never had a nigger cock\" https://t.co/JF9o9vjcBL\n",
            "Predicted:  1.0174234 Actual:  1 \n",
            "\n",
            "Any pregnant bitches at centreville I should know about in about to move there next ... &#8212; Idk.. I dont go to cville http://t.co/Hq4Q6zfwjh\n",
            "Predicted:  1.0088794 Actual:  1 \n",
            "\n",
            "&#8220;@Ditto_Guwop: All these hoes been passed around to a Cleveland niggah&#8221;\n",
            "Predicted:  0.99678695 Actual:  1 \n",
            "\n",
            "&#8220;@MomMeMustHaves: MMMH Daily is out! http://t.co/bPtRtXcel0 Stories via @KristinCruz&#8221; @ExMoShow #yellow is IN! &amp; @romyraves luv the bling!\n",
            "Predicted:  2.0089505 Actual:  2 \n",
            "\n",
            "Thursdays really been trash this season @nfl\n",
            "Predicted:  1.9697828 Actual:  2 \n",
            "\n",
            "RT @ImLeslieChow: When you eat food that's too hot and start breathing like a retarded dragon.\n",
            "Predicted:  1.0733198 Actual:  1 \n",
            "\n",
            "remember going out to actually freak a bitch? yeah that vibe is back.\n",
            "Predicted:  1.0119063 Actual:  1 \n",
            "\n",
            "RT @TyeOnHi: that shit's for the birds\n",
            "Predicted:  1.0081773 Actual:  1 \n",
            "\n",
            "Briahna told me the best advice I ever gave her was that it \"aint nothing to cut dat bitch off\" lmao.\n",
            "Predicted:  1.0108104 Actual:  1 \n",
            "\n",
            "cut that bitch off\n",
            "Predicted:  0.99368554 Actual:  1 \n",
            "\n",
            "I wish faggots like @tyga would stop making music, rack city was fucking awful. Get the fuck outta michigan.\n",
            "Predicted:  -0.023675438 Actual:  0 \n",
            "\n",
            "RT @KINGTUNCHI_: Fucking with a bad bitch you gone need some money lil homie!\n",
            "Predicted:  1.0106555 Actual:  1 \n",
            "\n",
            "RT @liyyy_: yall females really be cool with cuffin hoe ass niggas &#128514; nope. couldn't be me.\n",
            "Predicted:  0.9975831 Actual:  1 \n",
            "\n",
            "RT @ddebrinar: Smh, what a hoe. You just couldn't wait. @NayaRivera\n",
            "Predicted:  1.0149453 Actual:  1 \n",
            "\n",
            "@tay_baybay_12 pussy heels!! Haha\n",
            "Predicted:  0.9881985 Actual:  1 \n",
            "\n",
            "&#128077;RT @kwagiheath: One'a y'all b!tches gon end up dead over a screen shot thinkn that sh!t funny...ain't too many niccas gon laugh at that b!\n",
            "Predicted:  0.97198105 Actual:  1 \n",
            "\n",
            "Seen niccas come up ... I seen niccas fall\n",
            "Predicted:  0.98152703 Actual:  1 \n",
            "\n",
            "These people at jury selection are retarded\n",
            "Predicted:  0.97426623 Actual:  1 \n",
            "\n",
            "#SignsOfCockBlockin ----&gt;RT @tribexyunglion: Niggahs telling hoes I'm down talking them just so I can't get on &#128514; #FuckNiggahs\n",
            "Predicted:  1.019861 Actual:  1 \n",
            "\n",
            "RT @KayciMalynn: @__0utcast___ hey cunt, I miss you too &#128532;\n",
            "Predicted:  1.0085822 Actual:  1 \n",
            "\n",
            "Is Hillary the &#8216;dodo bird&#8217; candidate? http://t.co/YfUbgwQ4tw via @worldnetdaily\n",
            "Predicted:  1.8977487 Actual:  2 \n",
            "\n",
            "@bill_gaines @MorningJoe ATF is in charge of prosecuting cases and the #teabagger Republicans won't confirm a director to lead the agency.\n",
            "Predicted:  1.1158022 Actual:  1 \n",
            "\n",
            "@Mike_Stud touch my throbbing pussy\n",
            "Predicted:  1.0009987 Actual:  1 \n",
            "\n",
            "My phone acting retarded\n",
            "Predicted:  1.0117406 Actual:  1 \n",
            "\n",
            "bitch I might b\n",
            "Predicted:  0.99532235 Actual:  1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdEBerLo3A0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0148a0db-a541-4b02-f8f7-289778fded95"
      },
      "source": [
        "print('Average prediction difference: ', diff / num_predictions)"
      ],
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average prediction difference:  0.022747845947742464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCz57_-QYAhk",
        "colab_type": "text"
      },
      "source": [
        "### Generate TF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9eUm375X_Is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37639d43-968d-471f-b4af-8c73a775d77c"
      },
      "source": [
        "saved_model_dir = '/content/profanity_check_tuning'\n",
        "tf.saved_model.save(combined_model, saved_model_dir)"
      ],
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/profanity_check_tuning/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/profanity_check_tuning/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}