{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "profanity_check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9MLNVNgFA+z2zaDerQfC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinyueZ/flutter-web-profanity-check/blob/master/machine_learning/profanity_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEdwzLodYZ8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QAxRk_QYnVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import itertools\n",
        "\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYiXdRsK3jIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = keras.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIMZjQ_wYziS",
        "colab_type": "code",
        "outputId": "8fa9fc22-f62d-4d94-a313-4bc83eaed4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raXD5xU1Y1J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download dataset\n",
        "URL = \"https://dl.dropbox.com/s/ewpit86gekpiwk5/hate_dirty_peech_labeled_data.tsv\"\n",
        "path = tf.keras.utils.get_file(URL.split('/')[-1], URL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jd5izwxZFbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the data to a Pandas data frame\n",
        "data = pd.read_csv(path, sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGh-BZupZYvu",
        "colab_type": "code",
        "outputId": "c43ad0d1-8e2f-431e-b279-a27ff877a35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Shuffle the data\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "# Print the first first five rows as default\n",
        "data.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3762</th>\n",
              "      <td>3877</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>@KaylahPrettyMom lmao girlllaaaa I don't like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2103</th>\n",
              "      <td>2153</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>This be me &amp;#1041204;&amp;#1041204;&amp;#1041204;  Cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21729</th>\n",
              "      <td>22200</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>These bitches really be out here on backpage h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21195</th>\n",
              "      <td>21662</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Stupid bitches.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22637</th>\n",
              "      <td>23122</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>What's this bitch look like y'all &amp;#8220;@pear...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                              tweet\n",
              "3762         3877  ...  @KaylahPrettyMom lmao girlllaaaa I don't like ...\n",
              "2103         2153  ...   This be me &#1041204;&#1041204;&#1041204;  Cu...\n",
              "21729       22200  ...  These bitches really be out here on backpage h...\n",
              "21195       21662  ...                                    Stupid bitches.\n",
              "22637       23122  ...  What's this bitch look like y'all &#8220;@pear...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vayQEeh0IJ_",
        "colab_type": "code",
        "outputId": "995156b5-2ae3-4fe6-a60b-0cfab731751d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Clean data\n",
        "data = data[pd.notnull(data['class'])]\n",
        "data = data[pd.notnull(data['tweet'])]\n",
        "data = data.drop(data.columns[0], axis=1) \n",
        "data = data.drop(columns=['count', 'hate_speech', 'offensive_language', 'neither']) \n",
        " \n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem)) \n",
        "\n",
        "data[\"label\"] = data[\"class\"]\n",
        "\n",
        "# class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n",
        "data['class'].astype(str)\n",
        "data = data.replace({'class': {0: \"hate speech\", 1: \"offensive language\", 2: \"neither\"}})\n",
        "\n",
        "# Print the first first five rows as default\n",
        "data.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3762</th>\n",
              "      <td>neither</td>\n",
              "      <td>lmao girlllaaaa i dont like em chunky anymore...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2103</th>\n",
              "      <td>offensive language</td>\n",
              "      <td>this be me 104120410412041041204  cuh went fr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21729</th>\n",
              "      <td>offensive language</td>\n",
              "      <td>these bitches really be out here on backpage h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21195</th>\n",
              "      <td>offensive language</td>\n",
              "      <td>stupid bitches</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22637</th>\n",
              "      <td>offensive language</td>\n",
              "      <td>whats this bitch look like yall 8220 add me on...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    class  ... label\n",
              "3762              neither  ...     2\n",
              "2103   offensive language  ...     1\n",
              "21729  offensive language  ...     1\n",
              "21195  offensive language  ...     1\n",
              "22637  offensive language  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjWjj-AcuW19",
        "colab_type": "code",
        "outputId": "136f1162-1c04-430b-dc24-4aedfaff4a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Split data into train and test\n",
        "train_size = int(len(data) * .95)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(data) - train_size))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 23537\n",
            "Test size: 1239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubYRX8zDulje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features to train\n",
        "tweet_train = data['tweet'][:train_size]\n",
        "class_train = data['class'][:train_size]\n",
        "\n",
        "# Labels (class types)\n",
        "labels_train = data['label'][:train_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtI_IxF4vIUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features for test\n",
        "tweet_test = data['tweet'][train_size:]\n",
        "class_test = data['class'][train_size:]\n",
        "\n",
        "# Labels for test\n",
        "labels_test = data['label'][train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j3gc024xtmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 15000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df7fvZtEvl5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
        "tokenize.fit_on_texts(tweet_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVcTXjWyv-ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_train = tokenize.texts_to_matrix(tweet_train)\n",
        "bow_test = tokenize.texts_to_matrix(tweet_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z17N6DLBwaKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(class_train)\n",
        "class_train = encoder.transform(class_train)\n",
        "class_test = encoder.transform(class_test)\n",
        "num_classes = np.max(class_train) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxyDdsB7wm8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_train = keras.utils.to_categorical(class_train, num_classes)\n",
        "class_test = keras.utils.to_categorical(class_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW29eoPIw0PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_inputs = layers.Input(shape=(vocab_size,))\n",
        "class_inputs = layers.Input(shape=(num_classes,))\n",
        "merged_layer = layers.concatenate([bow_inputs, class_inputs])\n",
        "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
        "predictions = layers.Dense(1)(merged_layer)\n",
        "wide_model = keras.Model(inputs=[bow_inputs, class_inputs], outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhKIt_cFVckL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = \"mse\"\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHmKzUW0yQGB",
        "colab_type": "code",
        "outputId": "11684e07-7cad-4e9d-f466-e046c2e1b838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "wide_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "wide_model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 15000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 15003)        0           input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 256)          3841024     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            257         dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,841,281\n",
            "Trainable params: 3,841,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "het-rWCeyTf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_embed = tokenize.texts_to_sequences(tweet_train)\n",
        "test_embed = tokenize.texts_to_sequences(tweet_test)\n",
        "\n",
        "max_seq_length = 170\n",
        "train_embed = keras.preprocessing.sequence.pad_sequences(train_embed, maxlen=max_seq_length, padding=\"post\")\n",
        "test_embed = keras.preprocessing.sequence.pad_sequences(test_embed, maxlen=max_seq_length, padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYk1CN48yfos",
        "colab_type": "code",
        "outputId": "2e2f06a2-833d-4ae4-fb07-19bafe9293f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
        "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
        "embedding = layers.Flatten()(embedding)\n",
        "embed_out = layers.Dense(1)(embedding)\n",
        "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
        "deep_model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 170)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 170, 8)            120000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1360)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 1361      \n",
            "=================================================================\n",
            "Total params: 121,361\n",
            "Trainable params: 121,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8h2LdURzCBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deep_model.compile(loss=loss, optimizer=optimizer,  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaDpfzI-zKmY",
        "colab_type": "code",
        "outputId": "a09a6b39-01b4-4e3e-cb33-4be1259f8846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
        "merged_out = layers.Dense(1)(merged_out)\n",
        "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
        "combined_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "combined_model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 15000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 170)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 15003)        0           input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 170, 8)       120000      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 256)          3841024     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1360)         0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            257         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            1361        flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 2)            0           dense_5[0][0]                    \n",
            "                                                                 dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            3           concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 3,962,645\n",
            "Trainable params: 3,962,645\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvOrwHfaXA4W",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcaoQcM-VC4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeRxnt9mzg8n",
        "colab_type": "code",
        "outputId": "36411d85-6e4d-4e25-b292-241458d91fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "history = combined_model.fit([bow_train, class_train] + [train_embed], labels_train, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.0847 - accuracy: 0.7971\n",
            "Epoch 2/10\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.0116 - accuracy: 0.8322\n",
            "Epoch 3/10\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 0.0056 - accuracy: 0.8327\n",
            "Epoch 4/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 0.0026 - accuracy: 0.8328\n",
            "Epoch 5/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 0.0015 - accuracy: 0.8328\n",
            "Epoch 6/10\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 0.0011 - accuracy: 0.8328\n",
            "Epoch 7/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 9.3734e-04 - accuracy: 0.8328\n",
            "Epoch 8/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 9.6242e-04 - accuracy: 0.8328\n",
            "Epoch 9/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 9.9214e-04 - accuracy: 0.8328\n",
            "Epoch 10/10\n",
            "184/184 [==============================] - 9s 47ms/step - loss: 9.9978e-04 - accuracy: 0.8328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AXPzBxEzn3r",
        "colab_type": "code",
        "outputId": "3618ce3c-d998-4b2f-cad6-e7c5f42aaa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "combined_model.evaluate([bow_test, class_test] + [test_embed], labels_test, batch_size=batch_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 0.8168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0019928913097828627, 0.8167877197265625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlX3VPcHz5Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = combined_model.predict([bow_test, class_test] + [test_embed])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Edoojgg27PF",
        "colab_type": "code",
        "outputId": "f311c215-d642-4e1c-cc9b-a9752ae12a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_predictions = 40\n",
        "diff = 0\n",
        "\n",
        "for i in range(num_predictions):\n",
        "    val = predictions[i]\n",
        "    print(tweet_test.iloc[i])\n",
        "    print('Predicted: ', val[0], 'Actual: ', labels_test.iloc[i], '\\n')\n",
        "    diff += abs(val[0] - labels_test.iloc[i])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8220  coolin my nig   voice8221 uhhee   laugh\n",
            "Predicted:  1.0074544 Actual:  1 \n",
            "\n",
            "lookin at u hoes federalboobieinspector \n",
            "Predicted:  0.9991706 Actual:  1 \n",
            "\n",
            " im a lil nigga wait till you see nigga you aint ready im from chicago boy i aint no pussy from the burbs just wait\n",
            "Predicted:  0.9867027 Actual:  1 \n",
            "\n",
            "this does create a slippery slope tho  players gonna have to watch they mouth too  no tolerance for ignorance anymore\n",
            "Predicted:  1.9856583 Actual:  2 \n",
            "\n",
            " bitch i juss askd yu uh question yo ole choppa bullet head ahh\n",
            "Predicted:  0.97320986 Actual:  1 \n",
            "\n",
            "8220 8220 lmao nvm8221 thats right bitch8221 go drink some warm milk and go to bed\n",
            "Predicted:  1.0005717 Actual:  1 \n",
            "\n",
            " straight pussy\n",
            "Predicted:  0.9939398 Actual:  1 \n",
            "\n",
            "aint shit without my scale bitch i live that bag life\n",
            "Predicted:  0.97669524 Actual:  1 \n",
            "\n",
            "    lmao nigga yo avi so trash my phone wont even load that shit\n",
            "Predicted:  0.98152834 Actual:  1 \n",
            "\n",
            "  main bitches saying i hate a send me a pic ass nigga be answering every single one of dj ricearonis request\n",
            "Predicted:  1.0016733 Actual:  1 \n",
            "\n",
            " my current favorite line is shea moisture its at target and cvs great for dry curly andor colored hair\n",
            "Predicted:  1.984206 Actual:  2 \n",
            "\n",
            " niggashad gifted they sound like soulless cunts\n",
            "Predicted:  1.0039858 Actual:  1 \n",
            "\n",
            " word bird\n",
            "Predicted:  2.0046678 Actual:  2 \n",
            "\n",
            "    somebody whos that much of a moron and a pussy doesnt belong on the force\n",
            "Predicted:  1.0229893 Actual:  1 \n",
            "\n",
            "   you bitch ass nigga\n",
            "Predicted:  1.0031534 Actual:  1 \n",
            "\n",
            " faggot\n",
            "Predicted:  0.013083199 Actual:  0 \n",
            "\n",
            "niggas wonder why bitches be on that fucc a nigga shit cuz these niggas be on that she just another bitch shit 128175\n",
            "Predicted:  0.97363317 Actual:  1 \n",
            "\n",
            " tho i hate when bitches twerk to slow songs  128530128074128162\n",
            "Predicted:  0.9974557 Actual:  1 \n",
            "\n",
            "im mattwho da boy hoe check me out i do some amazing shit\n",
            "Predicted:  0.9919108 Actual:  1 \n",
            "\n",
            " yeah hoe ass nigga 128532128532128532\n",
            "Predicted:  1.000598 Actual:  1 \n",
            "\n",
            " genius the politically correct term would be intellectually disabled its highly offensive to use the word retarded\n",
            "Predicted:  1.9797308 Actual:  2 \n",
            "\n",
            "8220 i can believe that wiz khalifa and that one bald bitch are getting divorced 8221\n",
            "Predicted:  0.9992519 Actual:  1 \n",
            "\n",
            " budah  aye bro you kno how this shit go we in this bitch solid af running free the 1st\n",
            "Predicted:  0.968408 Actual:  1 \n",
            "\n",
            " dm me your number hoe\n",
            "Predicted:  0.9943453 Actual:  1 \n",
            "\n",
            "i aint going to movies hoe we straight sexing\n",
            "Predicted:  0.9931533 Actual:  1 \n",
            "\n",
            "8220brown30 frogger best game ever8221 only cuz you suck at flappy bird\n",
            "Predicted:  2.0120564 Actual:  2 \n",
            "\n",
            "i cant argue with a bitch over a nigga\n",
            "Predicted:  0.9931007 Actual:  1 \n",
            "\n",
            "8220sez why is everyone who thinks youre an unfunny pandering jizzbag automatically a troll 8221  and he hate colored folk\n",
            "Predicted:  1.0164653 Actual:  1 \n",
            "\n",
            "people who never use any hair product are unkept white trash douche bags\n",
            "Predicted:  0.9919099 Actual:  1 \n",
            "\n",
            "honestly i just do it for the bitch mob\n",
            "Predicted:  1.0067677 Actual:  1 \n",
            "\n",
            "bruh lmaoo 8220 them hoes was nasty but i kept eating them  what the fuck happened to these \n",
            "Predicted:  1.003854 Actual:  1 \n",
            "\n",
            " its fucking real retard holy fuck can you not read my tweets fucktard\n",
            "Predicted:  0.99094284 Actual:  1 \n",
            "\n",
            "ay yall heard that rich gang tape thou that bitch on flame128293\n",
            "Predicted:  0.98298067 Actual:  1 \n",
            "\n",
            "   that bitch wanna ignore my text wait till she get off work  rt  caption this \n",
            "Predicted:  1.0093317 Actual:  1 \n",
            "\n",
            "  to recap dem governor candidate in sc calls the gop candidate a whore txdem gov candidate mocks the gop candidate8217s di8230\n",
            "Predicted:  1.1110437 Actual:  1 \n",
            "\n",
            "jj watt was on his grown man shit all night now lets get it yankees\n",
            "Predicted:  1.0232401 Actual:  1 \n",
            "\n",
            "yankee homeruns make me all tingly\n",
            "Predicted:  1.9719827 Actual:  2 \n",
            "\n",
            "just touch down in jamaica tryna smoke two acres  send a nigguh to his makerr\n",
            "Predicted:  1.0031918 Actual:  1 \n",
            "\n",
            " bwahaaaa i just choked on an oreo cookie im figuring this may have something to do with it \n",
            "Predicted:  2.0294857 Actual:  2 \n",
            "\n",
            "  if my son ever turn out gay ima have to get his mom and let this nigga know what a pussy feel like\n",
            "Predicted:  1.0225879 Actual:  1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdEBerLo3A0R",
        "colab_type": "code",
        "outputId": "007f30ae-4c14-41ad-fb1a-fa4a6c55f26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Average prediction difference: ', diff / num_predictions)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average prediction difference:  0.014657113933935761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCz57_-QYAhk",
        "colab_type": "text"
      },
      "source": [
        "### Generate TF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9eUm375X_Is",
        "colab_type": "code",
        "outputId": "b4840cf1-a613-4fac-b6b3-6ac4d2fb02ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "saved_model_dir = '/content/profanity_check_tuning'\n",
        "tf.saved_model.save(combined_model, saved_model_dir)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/profanity_check_tuning/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}